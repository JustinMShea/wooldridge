---
title: "wooldridge-vignette"
author: "Justin M Shea"
date: ' '
output:
  pdf_document:
    toc: yes
  rmarkdown::html_document:
    toc: yes
vignette: >
  %\VignetteIndexEntry{wooldridge-vignette}  
  %\VignetteEngine{knitr::rmarkdown}  
  %\VignetteEncoding{UTF-8}


---

\newpage

## Introduction

This vignette contains examples from every chapter of _Introductory Econometrics: A Modern Approach_ by Jeffrey M. Wooldridge. Each example illustrates how to load data, build econometric models, and compute estimates with **R**.

Economics students new to both econometrics and **R** may find the introduction to both a bit challenging. In particular, the process of loading and preparing data prior to building one's first econometric model can present challenges. The `wooldridge` data package aims to lighten this task. It contains 105 data sets from _Introductory Econometrics: A Modern Approach_, and will load any set by typing its name into the `data()` function.

While the course companion site also provides publicly available data sets for Eviews, Excel, MiniTab, and Stata commercial software, **R** is the open source option. Furthermore, using **R** while building a foundation in econometrics, can become the first step in a student's journey toward using the most innovative new methods in statistical computing for handling larger, more modern data sets.

In addition, please visit the **Appendix** for sources on using R for econometrics. For example, an excellent reference is [_"Using R for Introductory Econometrics"_ by Florian Hess](http://www.urfie.net/index.html), written to compliment _Introductory Econometrics: A Modern Approach_. The full text can be viewed on the book website.

Now, load the `wooldridge` package and lets get started.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
library(wooldridge)
```

```{r, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}
library(stargazer)
```

\newpage

## Chapter 2: The Simple Regression Model

**`Example 2.10:` A Log Wage Equation**


$$\widehat{log(wage)} = \beta_0 + \beta_1educ$$

Load the `wage1` data.

```{r}
data("wage1")
```

Estimate a linear relationship between the _log of wage_ and _education_.

```{r}
log_wage_model <- lm(lwage ~ educ, data = wage1)
```

Print the results. I'm using the `stargazer` package to print the model results in a clean and easy to read format. See the bibliography for more information.

```{r, results = 'asis', warning=FALSE, message=FALSE}
stargazer(log_wage_model, single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 3: Multiple Regression Analysis: Estimation

**`Example 3.2:` Hourly Wage Equation**

$$\widehat{log(wage)} = \beta_0 + \beta_1educ + \beta_3exper + \beta_4tenure$$

Estimate the model regressing _education_, _experience_, and _tenure_ against _log(wage)_.

```{r}
hourly_wage_model <- lm(lwage ~ educ + exper + tenure, data = wage1)
```

Print the estimated model coefficients:

```{r, results = 'asis', warning=FALSE, message=FALSE}
stargazer(hourly_wage_model,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 4: Multiple Regression Analysis: Inference

**`Example 4.7` Effect of Job Training on Firm Scrap Rates**


Load the `jtrain` data set and if you are using R Studio, `View` the data set.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
data("jtrain")
```

```{r, echo = TRUE, eval = FALSE, warning=FALSE}
View(jtrain)
```

Create a logical index, identifying which observations occur in 1987 and are non-union.

```{r} 
index <- jtrain$year == 1987 & jtrain$union == 0
```

Next, subset the jtrain data by the new index. This returns a data.frame of `jtrain` data of non-union firms for the year 1987.

```{r}
jtrain_1987_nonunion <- jtrain[index, ]
```

Now create the linear model regressing `hrsemp`(total hours training/total employees trained), the `lsales`(log of annual sales), and `lemploy`(the log of the number of the employees), against `lscrap`(the log of the scrape rate).

$$lscrap = \alpha + \beta_1 hrsemp + \beta_2 lsales + \beta_3 lemploy$$


```{r}
linear_model <- lm(lscrap ~ hrsemp + lsales + lemploy, data = jtrain_1987_nonunion)
```

Finally, print the complete summary statistic diagnostics of the model.

```{r, results = 'asis', warning=FALSE, message=FALSE}
stargazer(linear_model,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 5: Multiple Regression Analysis: OLS Asymptotics

**`Example 5.3:` Economic Model of Crime**


$$narr86 = \beta_0 + \beta_1pcnv + \beta_2avgsen + \beta_3tottime + \beta_4ptime86 + \beta_5qemp86 + \mu$$

$narr86:$ number of times arrested, 1986.

$pcnv:$ proportion of prior arrests leading to convictions.

$avgsen:$ average sentence served, length in months.

$tottime:$ time in prison since reaching the age of 18, length in months.

$ptime86:$ months in prison during 1986.

$qemp86:$ quarters employed, 1986.


Load the `crime1` data set.

```{r}
data("crime1")
```

Estimate the model.

```{r, tidy = TRUE}
restricted_model <- lm(narr86 ~ pcnv + ptime86 + qemp86, data = crime1)
```

Create a new variable `restricted_model_u` containing the residuals $\tilde{\mu}$ from the above regression.

```{r}
restricted_model_u <- restricted_model$residuals
```

Next, regress `pcnv, ptime86, qemp86, avgsen`, and `tottime`, against the residuals $\tilde{\mu}$ saved in `restricted_model_u`.

$$\tilde{\mu} = \beta_1pcnv + \beta_2avgsen + \beta_3tottime + \beta_4ptime86 + \beta_5qemp86$$


```{r, tidy = TRUE}
LM_u_model <- lm(restricted_model_u ~ pcnv + ptime86 + qemp86 + avgsen + tottime, data = crime1)

summary(LM_u_model)$r.square
```

$$LM = 2,725(0.0015)$$

```{r}
LM_test <- nobs(LM_u_model) * 0.0015

LM_test
```


```{r}
qchisq(1 - 0.10, 2)
```

The _p_-value is:
$$P(X^2_{2} > 4.09) \approx 0.129$$

```{r}
1-pchisq(LM_test, 2)
```

\newpage

## Chapter 6: Multiple Regression: Further Issues

**`Example 6.1:` Effects of Pollution on Housing Prices, standardized.**


$$price = \beta_0 + \beta_1nox + \beta_2crime + \beta_3rooms + \beta_4dist + \beta_5stratio + \mu$$

$price$: median housing price.

$nox$: Nitrous Oxide concentration; parts per million.

$crime$: number of reported crimes per capita.

$rooms$: average number of rooms in houses in the community.

$dist$: weighted distance of the community to 5 employment centers.

$stratio$: average student-teacher ratio of schools in the community.


$$\widehat{zprice} = \beta_1znox + \beta_2zcrime + \beta_3zrooms + \beta_4zdist + \beta_5zstratio$$

Load the `hprice2` data.


```{r}
data("hprice2")
```

Estimate the coefficient with the usual `lm` regression model but this time, standardized coefficients by wrapping each variable with R's `scale` function:

```{r, tidy = TRUE}
housing_standard <- lm(scale(price)~0+scale(nox)+scale(crime)+scale(rooms)+scale(dist) + scale(stratio), data = hprice2)
```

```{r, results = 'asis', warning=FALSE, message=FALSE}
stargazer(housing_standard,  single.row = TRUE, header = FALSE)
```


\newpage

**`Example 6.2:` Effects of Pollution on Housing Prices, Quadratic Interactive Term**

Modify the housing model, adding a quadratic term in _rooms_: 

$$log(price) = \beta_0 + \beta_1log(nox) + \beta_2log(dist) + \beta_3rooms + \beta_4rooms^2 + \beta_5stratio + \mu$$
```{r}
housing_interactive <- lm(lprice ~ lnox + log(dist) + rooms+I(rooms^2) + stratio, data = hprice2)
```

Compare the results with the model from `example 6.1`.

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(housing_standard, housing_interactive, single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 7: Multiple Regression Analysis with Qualitative Information 

**`Example 7.4:` Housing Price Regression, Qualitative Binary variable**

This time, use the `hrprice1` data.

```{r}
data("hprice1")
```

If you recently worked with `hrpice2`, it may be helpful to view the documentation on this data set and read the variable names.

```{r, eval=FALSE}
?hprice1
```

$$\widehat{log(price)} = \beta_0 + \beta_1log(lotsize) + \beta_2log(sqrft) + \beta_3bdrms + \beta_4colonial $$

Estimate the coefficients of the above linear model on the `hprice` data set.

```{r, tidy=TRUE}
housing_qualitative <- lm(lprice ~ llotsize + lsqrft + bdrms + colonial, data = hprice1)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(housing_qualitative,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 8: Heteroskedasticity

**`Example 8.9:` Determinants of Personal Computer Ownership**

$$\widehat{PC} = \beta_0 + \beta_1hsGPA + \beta_2ACT + \beta_3parcoll + \beta_4colonial $$

Load `gpa1` and create a new variable combining the `fathcoll` and `mothcoll`, into `parcoll`. This new column indicates if either parent went to college.

```{r}
data("gpa1")

gpa1$parcoll <- as.integer(gpa1$fathcoll==1 | gpa1$mothcoll)
```

```{r}
GPA_OLS <- lm(PC ~ hsGPA + ACT + parcoll, data = gpa1)
```

Calculate the weights and then pass them to the `weights` argument.

```{r}
weights <- GPA_OLS$fitted.values * (1-GPA_OLS$fitted.values)

GPA_WLS <- lm(PC ~ hsGPA + ACT + parcoll, data = gpa1, weights = 1/weights)
```

Compare the OLS and WLS model in the table below:

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(GPA_OLS, GPA_WLS,  single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 9: More on Specification and Data Issues

**`Example 9.8:` R&D Intensity and Firm Size**


$$rdintens = \beta_0 + \beta_1sales + \beta_2profmarg + \mu$$

Load the data and estimate the model.

```{r}
data("rdchem")
 
all_rdchem <- lm(rdintens ~ sales + profmarg, data = rdchem)
```

Plotting the data reveals the outlier on the far right of the plot, which will skew the results of our model.

```{r, tidy=TRUE}
plot_title <- "FIGURE 9.1: Scatterplot of R&D intensity against firm sales"
x_axis <- "firm sales (in millions of dollars)"
y_axis <- "R&D as a percentage of sales"

plot(rdintens ~ sales, pch = 21, bg = "lightgrey", data = rdchem, main = plot_title, xlab = x_axis, ylab = y_axis)
```

So, we can estimate the model without that data point to gain a better understanding of how `sales` and `profmarg` describe `rdintens` for most firms. We can use the `subset` argument of the linear model function to indicate that we only want to estimate the model using data that is less than the highest sales.

```{r}
smallest_rdchem <- lm(rdintens ~ sales + profmarg, data = rdchem, 
                      subset = (sales < max(sales)))
```

The table below compares the results of both models side by side. By removing the outlier firm, $sales$ become a more significant determination of R&D expenditures.

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(all_rdchem, smallest_rdchem,  single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 10: Basic Regression Analysis with Time Series Data

**`Example 10.2:` Effects of Inflation and Deficits on Interest Rates**

$$\widehat{i3} = \beta_0 + \beta_1inf_t + \beta_2def_t$$

```{r}
data("intdef")

tbill_model <- lm(i3 ~ inf + def, data = intdef)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(tbill_model, single.row = TRUE, header = FALSE)
```


**`Example 10.11:` Seasonal Effects of Antidumping Filings**

```{r, tidy=TRUE}
data("barium")
barium_imports <- lm(lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + afdec6, data = barium)
```

Estimate a new model, `barium_seasonal` which accounts for seasonality by adding dummy variables contained in the data. Compute the `anova` between the two models.

```{r, tidy=TRUE}
barium_seasonal <- lm(lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + afdec6 + feb + mar + apr + may + jun + jul + aug + sep + oct + nov + dec, data = barium)

barium_anova <- anova(barium_imports, barium_seasonal)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(barium_imports, barium_seasonal,  single.row = TRUE, header = FALSE)

stargazer(barium_anova,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 11: Further Issues in Using OLS with with Time Series Data

**`Example 11.7:` Wages and Productivity**


$$\widehat{log(hrwage_t)} = \beta_0 + \beta_1log(outphr_t) + \beta_2t + \mu_t$$


```{r}
data("earns")

wage_time <- lm(lhrwage ~ loutphr + t, data = earns)
```

```{r}
wage_diff <- lm(diff(lhrwage) ~ diff(loutphr), data = earns)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(wage_time, wage_diff,  single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 12: Serial Correlation and Heteroskedasticiy in Time Series Regressions

**`Example 12.4`: Prais-Winsten Estimation in the Event Study**

```{r, tidy=TRUE}
data("barium")
barium_model <- lm(lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + afdec6, data = barium)
# Load the `prais` package, use the `prais.winsten` function to estimate.
library(prais)
barium_prais_winsten <- prais.winsten(lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + afdec6, data = barium)
```

```{r}
barium_model
barium_prais_winsten
```


\newpage

**`Example 12.8:` Heteroskedasticity and the Efficient Markets Hypothesis**


$$return_t = \beta_0 + \beta_1return_{t-1} + \mu_t$$

```{r}
data("nyse")
 
return_AR1 <-lm(return ~ return_1, data = nyse)
```

$$\hat{\mu^2_t} = \beta_0 + \beta_1return_{t-1} + residual_t$$


```{r}
return_mu <- residuals(return_AR1)

mu2_hat_model <- lm(return_mu^2 ~ return_1, data = return_AR1$model)
```
```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(return_AR1, mu2_hat_model,  single.row = TRUE, header = FALSE)
```


\newpage

**`Example 12.9:` ARCH in Stock Returns**


$$\hat{\mu^2_t} = \beta_0 + \hat{\mu^2_{t-1}} + residual_t$$

We still have `return_mu` in the working environment so we can use it to create $\hat{\mu^2_t}$, (`mu2_hat`) and $\hat{\mu^2_{t-1}}$ (`mu2_hat_1`). Notice the use `R`'s matrix subset operations to perform the lag operation. We drop the first observation of `mu2_hat` and squared the results. Next, we remove the last observation of `mu2_hat_1` using the subtraction operator combined with a call to the `NROW` function on `return_mu`. Now, both contain $688$ observations and we can estimate a standard linear model.

```{r}
mu2_hat  <- return_mu[-1]^2

mu2_hat_1 <- return_mu[-NROW(return_mu)]^2

arch_model <- lm(mu2_hat ~ mu2_hat_1)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(arch_model, single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 13: Pooling Cross Sections across Time: Simple Panel Data Methods

**`Example 13.7:` Effect of Drunk Driving Laws on Traffic Fatalities**


$$\widehat{\Delta{dthrte}} = \beta_0 + \Delta{open} + \Delta{admin}$$

```{r}
data("traffic1")

DD_model <- lm(cdthrte ~ copen + cadmn, data = traffic1)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(DD_model,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 14: Advanced Panel Data Methods

**`Example 14.1:` Effect of Job Training on Firm Scrap Rates**

In this section, we will estimate a linear panel modeg using the `plm` function from the `plm: Linear Models for Panel Data` package. See the bibliography for more information.

```{r, tidy=TRUE}
library(plm)

data("jtrain")

scrap_panel <- plm(lscrap ~ d88 + d89 + grant + grant_1, data = jtrain,
            index = c('fcode','year'), model = 'within', effect ='individual')
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(scrap_panel,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 15: Instrumental Variables Estimation and Two Stage Least Squares

**`Example 15.1:` Estimating the Return to Education for Married Women**


$$log(wage) = \beta_0 + \beta_1educ + \mu$$

```{r, message=FALSE}
data("mroz")
wage_educ_model <- lm(lwage ~ educ, data = mroz)
```


$$\widehat{educ} = \beta_0 + \beta_1fatheduc$$

We run the typical linear model, but notice the use of the `subset` argument. `inlf` is a binary variable in which a value of 1 means they are "In the Labor Force". By sub-setting the `mroz` data.frame by observations in which `inlf==1`, only working women will be in the sample.

```{r}
fatheduc_model <- lm(educ ~ fatheduc, data = mroz, subset = (inlf==1))
```

In this section, we will perform an **Instrumental-Variable Regression**, using the  `ivreg` function in the `AER (Applied Econometrics with R)` package. See the bibliography for more information.

```{r, message=FALSE}
library("AER")
wage_educ_IV <- ivreg(lwage ~ educ | fatheduc, data = mroz)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(wage_educ_model, fatheduc_model, wage_educ_IV, single.row = TRUE, header = FALSE)
```


\newpage

**`Example 15.2:` Estimating the Return to Education for Men**


$$\widehat{educ} = \beta_0 + sibs$$

```{r, warning=FALSE}
data("wage2")
 
educ_sibs_model <- lm(educ ~ sibs, data = wage2)
```


$$\widehat{log(wage)} = \beta_0 + educ$$

Again, estimate the model using the  `ivreg` function in the `AER (Applied Econometrics with R)` package.

```{r, message=FALSE}
library("AER")

educ_sibs_IV <- ivreg(lwage ~ educ | sibs, data = wage2)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(educ_sibs_model, educ_sibs_IV, wage_educ_IV,  single.row = TRUE, header = FALSE)
```

\newpage

**`Example 15.5:` Return to Education for Working Women**


$$\widehat{log(wage)} = \beta_0 + \beta_1educ + \beta_2exper + \beta_3exper^2$$

Use the  `ivreg` function in the `AER (Applied Econometrics with R)` package to estimate.

```{r, tidy=TRUE}
data("mroz")
wage_educ_exper_IV <- ivreg(lwage ~ educ + exper + expersq | exper + expersq + motheduc + fatheduc, data = mroz)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE, echo=FALSE}
stargazer(wage_educ_exper_IV,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 16: Simultaneous Equations Models

**`Example 16.4:` INFLATION AND OPENNESS**


$$inf = \beta_{10} + \alpha_1open + \beta_{11}log(pcinc) + \mu_1$$
$$open = \beta_{20} + \alpha_2inf + \beta_{21}log(pcinc) + \beta_{22}log(land) + \mu_2$$

**`Example 16.6:` INFLATION AND OPENNESS**


$$\widehat{open} = \beta_0 + \beta_{1}log(pcinc) + \beta_{2}log(land)$$


```{r}
data("openness")
 
open_model <-lm(open ~ lpcinc + lland, data = openness)
```

$$\widehat{inf} = \beta_0 + \beta_{1}open + \beta_{2}log(pcinc)$$

Use the  `ivreg` function in the `AER (Applied Econometrics with R)` package to estimate.

```{r}
library(AER)

inflation_IV <- ivreg(inf ~ open + lpcinc | lpcinc + lland, data = openness)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(open_model, inflation_IV,  single.row = TRUE, header = FALSE)
```


\newpage


## Chapter 17: Limited Dependent Variable Models and Sample Selection Corrections

**`Example 17.3:` POISSON REGRESSION FOR NUMBER OF ARRESTS**

```{r, tidy=TRUE, warning=FALSE}
data("crime1")
```

Sometimes, when estimating a model with many variables, defining a `model` object containing the formula makes for much cleaner code. 

```{r, tidy=TRUE, warning=FALSE}
formula <- (narr86 ~ pcnv + avgsen + tottime + ptime86 + qemp86 + inc86 + black + hispan + born60)
```

Then, pass the `formula` object into the `lm` function, and define the `data` argument as usual. 

```{r, tidy=TRUE, warning=FALSE}
econ_crime_model <- lm(formula, data = crime1)
```

To estimate the `poisson` regression, use the general linear model function `glm` and define the `family` argument as `poisson`.

```{r, tidy=TRUE, warning=FALSE}
econ_crim_poisson <- glm(formula, data = crime1, family = poisson)
```

Use the `stargazer` package to easily compare diagnostic tables of both models.

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(econ_crime_model, econ_crim_poisson,  single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 18: Advanced Time Series Topics

**`Example 18.8:` FORECASTING THE U.S. UNEMPLOYMENT RATE**

```{r}
data("phillips")
```

$$\widehat{unemp_t} = \beta_0 + \beta_1unem_{t-1}$$

Estimate the linear model in the usual way and note the use of the `subset` argument to define data equal to and before the year 1996.

```{r}
unem_AR1 <- lm(unem ~ unem_1, data = phillips, subset = (year <= 1996))
```

$$\widehat{unemp_t} = \beta_0 + \beta_1unem_{t-1} + \beta_2inf_{t-1}$$

```{r}
unem_inf_VAR1 <- lm(unem ~ unem_1 + inf_1, data = phillips, subset = (year <= 1996))
```

```{r, results = 'asis', warning=FALSE, message=FALSE, echo=FALSE}
stargazer(unem_AR1, unem_inf_VAR1,  single.row = TRUE, header = FALSE)
```


\newpage


## Bibliography

Yves Croissant, Giovanni Millo (2008). _Panel Data Econometrics in R: The plm Package_. Journal of Statistical Software 27(2). URL www.jstatsoft.org/v27/i02/.


Marek Hlavac (2015). _stargazer: Well-Formatted Regression and Summary Statistics Tables_. R package version 5.2. https://CRAN.R-project.org/package=stargazer


Christian Kleiber and Achim Zeileis (2008). _Applied Econometrics with R_. New York:
Springer-Verlag. ISBN 978-0-387-77316-2. URL https://CRAN.R-project.org/package=AER


Franz Mohr (2015). _prais: Prais-Winsten Estimation Procedure for AR(1) Serial Correlation_. R package version 0.1.1. https://CRAN.R-project.org/package=prais


R Core Team (2017). _R: A language and environment for statistical computing_. 
R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.


Hadley Wickham and Winston Chang (2016). _devtools: Tools to Make Developing R Packages Easier_. R package version 1.12.0. https://CRAN.R-project.org/package=devtools


Hadley Wickham. _testthat: Get Started with Testing_. R package version 1.0.2. https://CRAN.R-project.org/package=testthat


Jeffrey M. Wooldridge (2013). _Introductory Econometrics: A Modern Approach_. 
Mason, Ohio :South-Western Cengage Learning.


Yihui Xie (2017). _knitr: A General-Purpose Package for Dynamic Report Generation in R_. R package version 1.16. https://CRAN.R-project.org/package=knitr


\newpage


# Appendix


###**Using R for Introductory Econometrics**

This is an excellent open source complimentary text to "Introductory Econometrics" by Jeffrey M. Wooldridge and should be your number one resource. This excerpt from the book's website:

>  This book introduces the popular, powerful and free programming language and software package R with a focus on the implementation of standard tools and methods used in econometrics. Unlike other books on similar topics, it does not attempt to provide a self-contained discussion of econometric models and methods. Instead, it builds on the excellent and popular textbook "Introductory Econometrics" by Jeffrey M. Wooldridge.

Hess, Florian. _Using R for Introductory Econometrics_. ISBN: 978-1-523-28513-6, CreateSpace Independent Publishing Platform, 2016, Dusseldorf, Germany. 

[url: https://urfie.net](https://urfie.net).


###**Applied Econometrics with R**

From the publisher's website:

>    This is the first book on applied econometrics using the R system for statistical computing and graphics. It presents hands-on examples for a wide range of econometric models, from classical linear regression models for cross-section, time series or panel data and the common non-linear models of microeconometrics such as logit, probit and tobit models, to recent semiparametric extensions. In addition, it provides a chapter on programming, including simulations, optimization, and an introduction to R tools enabling reproducible econometric research. An R package accompanying this book, AER, is available from the Comprehensive R Archive Network (CRAN) at http://CRAN.R-project.org/package=AER.

Kleiber, Christian  and Achim Zeileis. _Applied Econometrics with R_. ISBN 978-0-387-77316-2,
Springer-Verlag, 2008, New York. [http://www.springer.com/us/book/9780387773162](http://www.springer.com/us/book/9780387773162)






